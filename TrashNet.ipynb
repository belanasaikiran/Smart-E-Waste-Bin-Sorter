{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7czcAxS8WVG",
        "outputId": "ed534161-7a56-42d2-9f01-6ccd629d9369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.16.1 in /usr/local/lib/python3.12/dist-packages (2.16.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (3.15.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (4.25.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (1.76.0)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.16.1) (2.16.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.45.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.16.1 keras numpy opencv-python matplotlib scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ml_dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTxPWbxm-1q7",
        "outputId": "47783f34-1b4c-40f1-c0d0-a00e69977f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (0.3.2)\n",
            "Collecting ml_dtypes\n",
            "  Using cached ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from ml_dtypes) (1.26.4)\n",
            "Using cached ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
            "Installing collected packages: ml_dtypes\n",
            "  Attempting uninstall: ml_dtypes\n",
            "    Found existing installation: ml-dtypes 0.3.2\n",
            "    Uninstalling ml-dtypes-0.3.2:\n",
            "      Successfully uninstalled ml-dtypes-0.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.16.1 requires ml-dtypes~=0.3.1, but you have ml-dtypes 0.5.3 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.16.1 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.16.1 which is incompatible.\n",
            "tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.16.1 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml_dtypes-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h90QXfaWfkGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -r data/\n",
        "# !rm dataset-resized.zip\n",
        "!unzip -q dataset-resized.zip -d data"
      ],
      "metadata": {
        "id": "mqUFeymOCHxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "e8KjW8gg8gAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = 'data/dataset-resized'"
      ],
      "metadata": {
        "id": "f0jYHRKLCZ9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "id": "dxoyaAl1826Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.4,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    brightness_range=[0.8,1.2],\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9GG0HRQCcx1",
        "outputId": "0e82aa21-87d5-4acd-ad60-ace46e071b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1548 images belonging to 5 classes.\n",
            "Found 385 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Lightweight Model (MobileNetV2)"
      ],
      "metadata": {
        "id": "3NfzvWr286tB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(128,128,3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "\n",
        "base.trainable = True\n",
        "for layer in base.layers[:-10]:  # unfreeze only top 10 layers\n",
        "    layer.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6\n",
        ")\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=5, restore_best_weights=True\n",
        ")\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=30,\n",
        "    callbacks=[callback, early_stop]\n",
        ")"
      ],
      "metadata": {
        "id": "aJtc8b8M8q_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c8c0ee-abb3-46fc-b70b-c30a095ca3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 887ms/step - accuracy: 0.1862 - loss: 2.2409 - val_accuracy: 0.2156 - val_loss: 2.1280 - learning_rate: 1.0000e-05\n",
            "Epoch 2/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 795ms/step - accuracy: 0.3044 - loss: 1.8260 - val_accuracy: 0.3325 - val_loss: 1.7468 - learning_rate: 1.0000e-05\n",
            "Epoch 3/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 818ms/step - accuracy: 0.4079 - loss: 1.5271 - val_accuracy: 0.3688 - val_loss: 1.6573 - learning_rate: 1.0000e-05\n",
            "Epoch 4/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 885ms/step - accuracy: 0.4338 - loss: 1.4139 - val_accuracy: 0.4052 - val_loss: 1.5770 - learning_rate: 1.0000e-05\n",
            "Epoch 5/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 809ms/step - accuracy: 0.5150 - loss: 1.2841 - val_accuracy: 0.4727 - val_loss: 1.3872 - learning_rate: 1.0000e-05\n",
            "Epoch 6/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 806ms/step - accuracy: 0.5311 - loss: 1.2364 - val_accuracy: 0.4883 - val_loss: 1.3523 - learning_rate: 1.0000e-05\n",
            "Epoch 7/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 809ms/step - accuracy: 0.5607 - loss: 1.1295 - val_accuracy: 0.4831 - val_loss: 1.3460 - learning_rate: 1.0000e-05\n",
            "Epoch 8/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 804ms/step - accuracy: 0.5529 - loss: 1.1300 - val_accuracy: 0.5065 - val_loss: 1.2485 - learning_rate: 1.0000e-05\n",
            "Epoch 9/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 802ms/step - accuracy: 0.6035 - loss: 1.0511 - val_accuracy: 0.4909 - val_loss: 1.2830 - learning_rate: 1.0000e-05\n",
            "Epoch 10/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 807ms/step - accuracy: 0.6252 - loss: 0.9988 - val_accuracy: 0.4935 - val_loss: 1.2124 - learning_rate: 1.0000e-05\n",
            "Epoch 11/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 821ms/step - accuracy: 0.6034 - loss: 0.9759 - val_accuracy: 0.5455 - val_loss: 1.1696 - learning_rate: 1.0000e-05\n",
            "Epoch 12/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 810ms/step - accuracy: 0.6515 - loss: 0.9022 - val_accuracy: 0.5143 - val_loss: 1.1823 - learning_rate: 1.0000e-05\n",
            "Epoch 13/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 865ms/step - accuracy: 0.6642 - loss: 0.8694 - val_accuracy: 0.5844 - val_loss: 1.1520 - learning_rate: 1.0000e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 811ms/step - accuracy: 0.6379 - loss: 0.9353 - val_accuracy: 0.5610 - val_loss: 1.0945 - learning_rate: 1.0000e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 794ms/step - accuracy: 0.6594 - loss: 0.8758 - val_accuracy: 0.5636 - val_loss: 1.0270 - learning_rate: 1.0000e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 806ms/step - accuracy: 0.6598 - loss: 0.8621 - val_accuracy: 0.5818 - val_loss: 1.0539 - learning_rate: 1.0000e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 813ms/step - accuracy: 0.6964 - loss: 0.8085 - val_accuracy: 0.6026 - val_loss: 1.0362 - learning_rate: 1.0000e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 810ms/step - accuracy: 0.6951 - loss: 0.8132 - val_accuracy: 0.5948 - val_loss: 1.0366 - learning_rate: 1.0000e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 913ms/step - accuracy: 0.6653 - loss: 0.8379 - val_accuracy: 0.5922 - val_loss: 0.9726 - learning_rate: 5.0000e-06\n",
            "Epoch 20/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 871ms/step - accuracy: 0.7154 - loss: 0.7828 - val_accuracy: 0.5740 - val_loss: 1.0579 - learning_rate: 5.0000e-06\n",
            "Epoch 21/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 825ms/step - accuracy: 0.7090 - loss: 0.7488 - val_accuracy: 0.6078 - val_loss: 1.0081 - learning_rate: 5.0000e-06\n",
            "Epoch 22/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 802ms/step - accuracy: 0.6993 - loss: 0.7773 - val_accuracy: 0.6078 - val_loss: 0.9861 - learning_rate: 5.0000e-06\n",
            "Epoch 23/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 810ms/step - accuracy: 0.7105 - loss: 0.8094 - val_accuracy: 0.6260 - val_loss: 0.9639 - learning_rate: 2.5000e-06\n",
            "Epoch 24/30\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 821ms/step - accuracy: 0.7046 - loss: 0.7678 - val_accuracy: 0.6078 - val_loss: 0.9821 - learning_rate: 2.5000e-06\n",
            "Epoch 25/30\n",
            "\u001b[1m20/49\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 701ms/step - accuracy: 0.7487 - loss: 0.6813"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_finetune = model.fit(train_gen, validation_data=val_gen, epochs=15)"
      ],
      "metadata": {
        "id": "2_5RqgUNqfFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52cfba94-3107-4103-d339-f40b636856b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 822ms/step - accuracy: 0.7244 - loss: 0.7553 - val_accuracy: 0.6182 - val_loss: 0.9561\n",
            "Epoch 2/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 821ms/step - accuracy: 0.7230 - loss: 0.7437 - val_accuracy: 0.6156 - val_loss: 0.9840\n",
            "Epoch 3/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 974ms/step - accuracy: 0.6774 - loss: 0.7986 - val_accuracy: 0.6130 - val_loss: 0.9746\n",
            "Epoch 4/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 809ms/step - accuracy: 0.6929 - loss: 0.8106 - val_accuracy: 0.6312 - val_loss: 0.9403\n",
            "Epoch 5/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 830ms/step - accuracy: 0.7344 - loss: 0.7284 - val_accuracy: 0.6260 - val_loss: 0.9370\n",
            "Epoch 6/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 813ms/step - accuracy: 0.7038 - loss: 0.7827 - val_accuracy: 0.6286 - val_loss: 0.9836\n",
            "Epoch 7/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 813ms/step - accuracy: 0.7175 - loss: 0.7362 - val_accuracy: 0.6260 - val_loss: 0.9214\n",
            "Epoch 8/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 827ms/step - accuracy: 0.7153 - loss: 0.7342 - val_accuracy: 0.6026 - val_loss: 0.9376\n",
            "Epoch 9/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 822ms/step - accuracy: 0.7257 - loss: 0.7186 - val_accuracy: 0.6338 - val_loss: 0.9006\n",
            "Epoch 10/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 820ms/step - accuracy: 0.7241 - loss: 0.7078 - val_accuracy: 0.6364 - val_loss: 0.9408\n",
            "Epoch 11/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 820ms/step - accuracy: 0.7086 - loss: 0.7446 - val_accuracy: 0.6338 - val_loss: 0.9260\n",
            "Epoch 12/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 823ms/step - accuracy: 0.7201 - loss: 0.7500 - val_accuracy: 0.6104 - val_loss: 0.9804\n",
            "Epoch 13/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 821ms/step - accuracy: 0.7192 - loss: 0.7322 - val_accuracy: 0.6519 - val_loss: 0.9252\n",
            "Epoch 14/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 821ms/step - accuracy: 0.7385 - loss: 0.6963 - val_accuracy: 0.6156 - val_loss: 0.9211\n",
            "Epoch 15/15\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 825ms/step - accuracy: 0.7348 - loss: 0.7112 - val_accuracy: 0.6390 - val_loss: 0.9261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "Y_pred = model.predict(val_gen)\n",
        "y_pred = Y_pred.argmax(axis=1)\n",
        "cm = confusion_matrix(val_gen.classes, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "\n",
        "print(classification_report(val_gen.classes, y_pred, target_names=val_gen.class_indices.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "iH-toLl8ltD9",
        "outputId": "9c5b613e-d6b3-498a-f0c6-01b2bf5e7896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 543ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       glass       0.22      0.31      0.26       100\n",
            "       metal       0.17      0.09      0.11        82\n",
            "       paper       0.23      0.22      0.22       118\n",
            "     plastic       0.23      0.26      0.24        96\n",
            "       trash       0.06      0.04      0.04        27\n",
            "\n",
            "    accuracy                           0.21       423\n",
            "   macro avg       0.18      0.18      0.18       423\n",
            "weighted avg       0.20      0.21      0.20       423\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pC9gxfTRqeH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate and Save Model"
      ],
      "metadata": {
        "id": "jUmoql5y8-CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = model.evaluate(val_gen)[1]\n",
        "print(f\"Validation Accuracy: {acc:.2f}\")\n",
        "\n",
        "model.save('trashnet_mobilenetv2.h5')\n"
      ],
      "metadata": {
        "id": "6kCU8JcM8s_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458b232f-4e2f-438e-a567-e546e9e66f22"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 599ms/step - accuracy: 0.6298 - loss: 0.8764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert to TensorFlow Lite (Quantized)"
      ],
      "metadata": {
        "id": "TxPhjrWr9Ane"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # full-int8 quantization\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('trashnet_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "id": "fn13uHEm8vOH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "a0f4c00c-43ea-4c19-bbd6-a3bc6f033ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute '_get_save_spec'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1963907684.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# full-int8 quantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trashnet_model.tflite'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1173\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_and_export_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_conversion_params_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m     \u001b[0melapsed_time_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m     graph_def, input_tensors, output_tensors, frozen_func = (\n\u001b[0;32m-> 1641\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_freeze_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m     )\n\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Re-throws the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m_freeze_keras_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1580\u001b[0m       \u001b[0;31m# signature including the batch dimension specified by the user.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m       \u001b[0;31m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m       input_signature = _model_input_signature(\n\u001b[0m\u001b[1;32m   1583\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_original_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/tflite_keras_util.py\u001b[0m in \u001b[0;36mmodel_input_signature\u001b[0;34m(model, keep_original_batch_size)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0minput_specs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_specs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     input_specs = model._get_save_spec(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m     85\u001b[0m         dynamic_batch=not keep_original_batch_size)\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_specs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute '_get_save_spec'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Model to Your Laptop"
      ],
      "metadata": {
        "id": "2XsyLp_o9DE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('trashnet_model.tflite')\n"
      ],
      "metadata": {
        "id": "CqnvCTFQ8xyN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}